# Ollama Configuration - Remote DGX Server
# Copy this file to .env and configure for your setup

# Ollama/vLLM server host (use localhost or IP address)
VLLM_HOST=192.168.68.100

# Ollama default port is 11434, vLLM default is 8000
VLLM_PORT=11434

# Model name that exists in your Ollama server
# Run: curl http://VLLM_HOST:11434/api/tags
# to see available models
VLLM_MODEL_NAME=qwen2.5:72b

# Optional: OpenRouter API key for fallback
# OPENROUTER_API_KEY=your_key_here
